#!/usr/bin/python
# -*- coding:utf-8 -*-
import os, sys
reload(sys)
sys.setdefaultencoding('utf-8')
import os.path
import sets
import time
import datetime
import urlparse
import pprocess
import shutil
import openpyxl
from openpyxl import load_workbook
from dbaseconfig import dbaseconfig
import dtexttokenizer as dtexttokenizer
import dtext4aVikash as datatextextract4a
from distutils.dir_util import copy_tree

class xlsxReader(object):
    def __init__(self):
        pass

    def readExcel(self, fname):
        excel_data = {}
        wb = load_workbook(filename=fname, data_only=True)
        sheet_names = wb.sheetnames
        for idx, sheet_name in enumerate(sheet_names):
            sheetObj = wb[sheet_name]
            excel_data[sheet_name] = []
            for rowid, rowObjs in enumerate(sheetObj.rows):
                row = []
                data_flag = 0
                for colid, cellObj in enumerate(rowObjs):
                    val = cellObj.value
                    if val is None:
                        val = ''
                    row.append(val)
                    if cellObj.value:
                        data_flag = 1
                if not data_flag: continue
                excel_data[sheet_name].append(row)
        return excel_data

class textdataextract4a(dbaseconfig):
    def __init__(self, projectid, urlid, agentid, mgmtid, userid, cfgfile, dtype='html'):
        dbaseconfig.__init__(self, projectid, urlid, agentid, mgmtid, userid, cfgfile)
        self.__dataclassifyopath = self.getsigdatapath(self.basepath, 'training', '')
        self.__doctype = dtype.lower()
        self.__dtype = dtype.lower()
        self.__dtype = 'html'
        self.__tmp_extract_opath = self.__dataclassifyopath[:]
        #self.__dtexttokenizerObj = dtexttokenizer.dtexttokenizer(109)
        self.__dtexttokenizerObj = dtexttokenizer.dtexttokenizer(110)
        print self.__dtexttokenizerObj
        self.get_taxonomy_categoryv4(0)
        self.__txtObj = datatextextract4a.datatextextract4a(projectid, urlid, agentid, mgmtid, userid, cfgfile, self.__dtexttokenizerObj, self.__dataclassifyopath, self.__doctype, self.__dtype)
        #self.__txtObj.dataextractinit()
        self.__doc_process_opath = self.getprocessdatapath(self.basepath, '')
        print self.__doc_process_opath
        print self.basepath
        print self.ipath
        print self.opath
        print self.__dataclassifyopath
        pass

    def __project_info(self):
        ttup = (self.projectid, self.urlid, self.userid, self.agentid, self.mgmtid)
        return ttup

    def __get_agentid_mgmtid_str(self, agentid, mgmtid):
        tmpstr = '%s_%s'%(str(agentid), str(mgmtid))
        return tmpstr

    def getdcdatapath(self, opath, *args):
        return self.getdatapath(opath, 'data', *args)

    def getdcinputpath(self, opath, *args):
        return self.getdatapath(opath, 'input', *args)

    def __get_urlid_inputpath(self):
        p = os.path.join(self.__dataclassifyopath[:], 'input', '')
        return p

    def createdir(self, fname):
        dirname = os.path.dirname(fname)
        if dirname and (not os.path.exists(dirname)):
            os.makedirs(dirname)
        return

    def __get_taxonomy_filename(self):
        p = self.__get_urlid_inputpath()
        tmptaxoname = 'taxonomy_%s_%s.xlsx' %(str(self.projectid), str(self.urlid))
        fname = os.path.join(p, tmptaxoname)
        return fname

    def __readExcel(self, ifname):
        resd = {}
        if os.path.isfile(ifname):
            xlsxObj = xlsxReader()
            resd = xlsxObj.readExcel(ifname)
        return resd

    def __get_project_taxonomy_data(self, rerun=0):
        resd0 = {}
        resd1 = {}
        if 1 and ((not resd0) or rerun):
            taxofname = self.__get_taxonomy_filename()
            tmpd = self.__readExcel(taxofname)
            taxodatalst = tmpd.get('Taxonomy', [])

            tmpd0 = {}
            tmpd1 = {}
            for i in range(1, len(taxodatalst)):
                each = taxodatalst[i]
                tmpcategoryname, tmpsectionname, tmpindex, tmptaxonomy, tmpdatatype, tmpclienttaxoraw, tmpclienttaxobulk, tmplookupcodes, tmpcurrency, tmpscale, tmpmeasurementunit, tmpscope, tmplookupusage, tmptaxotype, tmptargetcategory = each[:15]
                taxokeytup = (str(tmpcategoryname), str(tmpsectionname), str(tmptaxonomy))
                tmpd0[taxokeytup] = i
                tmpd1[str(tmptaxonomy)] = taxokeytup
                pass

            resd0['Taxonomy'] = taxodatalst[:]
            resd1['taxokeyindexd'] = tmpd0
            resd1['taxo2taxokeyd'] = tmpd1
            pass 
        return resd0, resd1

    def __get_taxonomy_categoryv4(self, opath, rerun=0):
        def updateds(k, v, d):
            if d.get(k, None) is None:
                d[k] = []
            d[k].append(v)
            return d
        ofname = self.getdcdatapath(opath, 'taxodata', 'taxoprocessdata_%s_%s.slv'%(str(self.projectid), str(self.urlid)))
        resd = self.read_from_shelve(ofname, {})
        if 1 and ((not resd) or rerun):
            taxofname = self.__get_taxonomy_filename()
            tmpd = self.__readExcel(taxofname)
            taxodatalst = tmpd.get('taxonomy_file', [])
            peerpairgrouplst = tmpd.get('Peer_Pair', [])
            if not taxodatalst:
                taxodatalst = tmpd.get('Taxonomy', [])
            if not peerpairgrouplst:
                peerpairgrouplst = tmpd.get('PeerandPairGroup', [])

            tmpdd = {}
            tmpdd['Target Known Entity'] = 'Category1_KnownType'
            tmpdd['Target Dynamic Entity'] = 'Category2_DynamicType'
            tmpdd['Target ExactPhrase Entity'] = 'Category3_ExactPhraseType'
            tmpdd['Target Interpreted Phrase, Entity or Semantic Attribute'] = 'Category4_InterpretedPhraseType'
            tmpdd['Target Interpreted Structural Chunk'] = 'Category5_InterpretedStructuralType'

            taoxpeerd = {}
            for i in range(1, len(taxodatalst)):
                each = taxodatalst[i]
                tmpcategoryname, tmpsectionname, tmpindex, tmptaxonomy, tmpdatatype, tmpclienttaxoraw, tmpclienttaxobulk, tmplookupcodes, tmpcurrency, tmpscale, tmpmeasurementunit, tmpscope, tmplookupusage, tmptaxotype, tmptargetcategory, tmpmultivalue = each[:16]
                tmptaxonomy = tmptaxonomy.strip()
                tmptaxocategorytypenorm = tmpdd.get(tmptargetcategory, '')
                vtup = (tmptaxonomy, tmptaxocategorytypenorm, tmptargetcategory, tmpdatatype, tmplookupusage, tmptaxotype)
                #taoxpeerd = updateds(('T1', i), vtup, taoxpeerd)
                taoxpeerd = updateds(('T2', tmptaxonomy), vtup, taoxpeerd)
                taoxpeerd = updateds(('T3', tmptaxocategorytypenorm), tmptaxonomy, taoxpeerd)
                taoxpeerd = updateds(('T4', tmplookupusage), tmptaxonomy, taoxpeerd)
                taoxpeerd = updateds(('T5', tmptaxotype), tmptaxonomy, taoxpeerd)
                pass

            for i in range(1, len(peerpairgrouplst)):
                tmptup = peerpairgrouplst[i]
                tmpcategoryname, tmpsectionname, tmptaxoindex, tmptaxoname, tmppeer, tmppair, tmpgivenderived, tmpminoccurance, tmpmaxoccurance = tmptup[:9]
                tmptaxoname = tmptaxoname.strip()
                tmppeer = tmppeer.strip()
                tmppair = tmppair.strip()
                vtup = (tmptaxoname, tmppeer, tmppair, tmpgivenderived.strip(), tmpminoccurance, tmpmaxoccurance)
                #taoxpeerd = updateds(('P1', i), vtup, taoxpeerd)
                taoxpeerd = updateds(('P2', tmptaxoname), vtup, taoxpeerd)
                taoxpeerd = updateds(('P3', tmppeer), tmptaxoname, taoxpeerd)
                taoxpeerd = updateds(('P4', tmppair), tmptaxoname, taoxpeerd)

            taoxpeerd2 = {}
            taxoheader = taxodatalst[0][:15]
            for i in range(1, len(taxodatalst)):
                each = taxodatalst[i]
                tmpcategoryname, tmpsectionname, tmpindex, tmptaxonomy, tmpdatatype, tmpclienttaxoraw, tmpclienttaxobulk, tmplookupcodes, tmpcurrency, tmpscale, tmpmeasurementunit, tmpscope, tmplookupusage, tmptaxotype, tmptargetcategory = each[:15]
                tmptaxonomy = tmptaxonomy.strip()
                for j in range(0, 15):
                    taoxpeerd2 = updateds(tmptaxonomy, (taxoheader[j], each[j]), taoxpeerd2)
                pass

            peerpairheader = peerpairgrouplst[0][:9] if peerpairgrouplst else []
            for i in range(1, len(peerpairgrouplst)):
                tmptup = peerpairgrouplst[i]
                tmpcategoryname, tmpsectionname, tmptaxoindex, tmptaxoname, tmppeer, tmppair, tmpgivenderived, tmpminoccurance, tmpmaxoccurance = tmptup[:9]
                for j in range(4, 9):
                    taoxpeerd2 = updateds(tmptaxoname, (peerpairheader[j], tmptup[j]), taoxpeerd2)
                pass


            # save
            resd = taoxpeerd2
            self.write_to_shelve(ofname, taoxpeerd2)
            print 'Writing:', ofname
            pass
        return resd

    def __get_taxonomy_index(self, opath, rerun=0):
        def updateds(k, v, d):
            if d.get(k, None) is None:
                d[k] = []
            d[k].append(v)
            return d
        ofname = self.getdcdatapath(opath, 'taxodata', 'taxoprocessdata_%s_%s.slv'%(str(self.projectid), str(self.urlid)))
        print ofname
        resd = self.read_from_shelve(ofname, {})
        if 1 and ((not resd) or rerun):
            taxofname = self.__get_taxonomy_filename()
            print taxofname
            tmpd = self.__readExcel(taxofname)
            taxodatalst = tmpd.get('taxonomy_file', [])
            peerpairgrouplst = tmpd.get('Peer_Pair', [])
            if not taxodatalst:
                taxodatalst = tmpd.get('Taxonomy', [])
            if not peerpairgrouplst:
                peerpairgrouplst = tmpd.get('PeerandPairGroup', [])
            newpeergrouplst = tmpd.get('PeerGroups_New', [])
            if not newpeergrouplst:
                newpeergrouplst = tmpd.get('Peer Groups New', [])

            tmpdd = {}
            tmpdd['Target Known Entity'] = 'Category1_KnownType'
            tmpdd['Target Dynamic Entity'] = 'Category2_DynamicType'
            tmpdd['Target ExactPhrase Entity'] = 'Category3_ExactPhraseType'
            tmpdd['Target Interpreted Phrase, Entity or Semantic Attribute'] = 'Category4_InterpretedPhraseType'
            tmpdd['Target Interpreted Structural Chunk'] = 'Category5_InterpretedStructuralType'

            taxod0 = {}
            taxoheader = taxodatalst[0][:16]
            taxoheader = [str(t).strip() for t in taxoheader]
            for j in range(0, len(taxoheader)):
                taxohdrn = taxoheader[j]
                taxod0 = updateds(('th1a', taxohdrn), j, taxod0)
                taxod0 = updateds(('th1b', j), taxohdrn, taxod0)
            taxod0 = updateds(('th1a', 'normnodetype'), len(taxoheader), taxod0)
            taxod0 = updateds(('th1b', len(taxoheader)), 'normnodetype', taxod0)

            for i in range(1, len(taxodatalst)):
                each = taxodatalst[i]
                each = [str(t).strip() for t in each]
                tmpcategoryname, tmpsectionname, tmpindex, tmptaxonomy, tmpdatatype, tmpclienttaxoraw, tmpclienttaxobulk, tmplookupcodes, tmpcurrency, tmpscale, tmpmeasurementunit, tmpscope, tmplookupusage, tmptaxotype, tmptargetcategory, tmpmultivalue = each[:16]
                tmptaxonomy = tmptaxonomy.strip()
                tmptaxocategorytypenorm = tmpdd.get(tmptargetcategory, '')
                vtup = (tmptaxonomy, tmptaxocategorytypenorm, tmptargetcategory, tmpdatatype, tmplookupusage, tmptaxotype)
                taxotup = (tmpcategoryname, tmpsectionname, tmpindex, tmptaxonomy, tmpdatatype, tmpclienttaxoraw, tmpclienttaxobulk, tmplookupcodes, tmpcurrency, tmpscale, tmpmeasurementunit, tmpscope, tmplookupusage, tmptaxotype, tmptargetcategory, tmpmultivalue, tmptaxocategorytypenorm)
                taxod0 = updateds(('T1', i), taxotup, taxod0)
                taxod0 = updateds(('T2', tmptaxonomy), i, taxod0)
                taxod0 = updateds(('T3', tmpcategoryname, tmpsectionname, tmptaxonomy), i, taxod0)
                for j in range(0, 16):
                    dval = each[j]
                    if not dval: continue
                    hdrval = taxoheader[j]
                    taxod0 = updateds(('T4', hdrval, dval), i, taxod0)
                pass

            ppmaxlen = 12
            ppgroupheader = newpeergrouplst[0][:ppmaxlen]
            ppgroupheader = [str(t).strip() for t in ppgroupheader]
            for j in range(0, len(ppgroupheader)):
                pphdrn = ppgroupheader[j]
                taxod0 = updateds(('ppgh1', pphdrn), j, taxod0)
                pass
            for i in range(1, len(newpeergrouplst)):
                tmptup = newpeergrouplst[i][:ppmaxlen]
                tmptup = [str(t).strip() for t in tmptup]
                tmptaxoname, tmppeergroup, tmpdependency, tmpdirectionality, tmpstructure, tmpnumerical, tmptimeseries, tmpsemantic, tmplogical, tmpconditional, tmpderived, tmpcomment = tmptup
                taxod0 = updateds(('PPG1', i), tmptup, taxod0)
                #taxod0 = updateds(('PPG2', tmptaxoname), i, taxod0)
                taxod0 = updateds(('PPG3', tmppeergroup), i, taxod0)
                for j in range(0, ppmaxlen):
                    dval = tmptup[j]
                    if not dval: continue
                    hdrval = ppgroupheader[j]
                    taxod0 = updateds(('PPG4', hdrval, dval), i, taxod0)
                pass

            # save
            resd = taxod0
            self.write_to_shelve(ofname, taxod0)
            print 'Writing:', ofname
            pass
        return resd

    def get_taxonomy_categoryv4(self, rerun=0):
        opath = self.__dataclassifyopath[:]
        #resd = self.__get_taxonomy_categoryv4(opath, rerun)
        resd = self.__get_taxonomy_index(opath, rerun)
        return resd

    def get_network_path(self, hostaddr, ipath):
        opath = ''
        if ipath[:14] == '/var/www/html/':
            tmp_path = ipath[14:]
            opath = 'http://%s/%s' %(str(hostaddr), str(tmp_path))
        else:
            opath = ipath[:]
        return opath

    def get_total_pages(self, opath, docid):
        total_pages = -1
        fname = os.path.join(opath, str(docid), 'pdf_total_pages')
        if os.path.isfile(fname):
            fp = open(fname, 'r')
            lines = fp.readlines()
            fp.close()
            lines = [line.strip() for line in lines if line.strip()]
            total_pages = int(lines[0])
        return total_pages

    def copy_remote_data_files(self, idocid, ipageno=1):
        def remotecopy(remotesrc, localdst):
            self.createdir(localdst)
            cmd = 'wget -q %s --directory-prefix=%s' %(str(remotesrc), str(localdst))
            os.system(cmd)
            return
        def remotecopy2(tmpdocid, tmppno, remotesrc, localdst):
            self.createdir(localdst)
            tmpfname = os.path.join(localdst, '%s_%s_body.html'%(str(tmpdocid), str(tmppno)))
            cmd = 'wget -q %s -O %s' %(str(remotesrc), tmpfname)
            os.system(cmd)
            return
        localdstpath = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), 'html', '')
        refurl02 = 'http://172.16.10.224/INFOSIEVE_PROJECTS/EQUITYGD/data/output/%s/html/%s_body.html'%(str(idocid), str(idocid))
        localfname = os.path.join(localdstpath, '%s_%s_body.html'%(str(idocid), str(ipageno)))
        if 1 and (not os.path.isfile(localfname)):
            #remotecopy(refurl02, localdstpath)
            remotecopy2(idocid, ipageno, refurl02, localdstpath)
            pass
        return localdstpath

    def copy_localhost_data_files(self, idocid, ipageno=1):
        localdstpath = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), '')
        for t in ['html/']:
            tmpdst = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), t, '')
            tmpsrc = os.path.join(self.__doc_process_opath, 'docs', str(idocid), t, '')
            if os.path.isdir(tmpsrc):
                self.createdir(tmpdst)
                copy_tree(tmpsrc, tmpdst)
            pass
        return localdstpath

    def copyhtmldocid(self, idocid):
        localpath = self.copy_remote_data_files(idocid)
        #localpath = self.copy_localhost_data_files(idocid)
        return

    def copy_remote_pdf_docid_data_files(self, idocid):
        def remote_dircopy(remotesrc, localdst):
            dircnt = 10
            self.createdir(localdst)
            cmd = 'wget -q --recursive --no-host-directories --no-parent --cut-dirs=%s --reject "index.html*" %s --directory-prefix=%s' %(str(dircnt), str(remotesrc), str(localdst))
            os.system(cmd)
            return
        localdstpath = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), '')
        html_path = 'http://172.16.20.10/INFOSIEVE_PROJECTS/HKSEGD/data/output/' 
        refutl01 = os.path.join(html_path, str(idocid))
        for t in ['pdf_total_pages']:
            tmplocaldstpath = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), '')
            tmpurl01 = 'http://172.16.20.10/INFOSIEVE_PROJECTS/HKSEGD/data/output/%s/%s'%(str(idocid), t)
            remote_dircopy(tmpurl01, tmplocaldstpath)
        for t in ['output_html/']:
            tmplocaldstpath = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), t)
            tmpurl01 = 'http://172.16.20.10/INFOSIEVE_PROJECTS/HKSEGD/data/output/%s/%s'%(str(idocid), t)
            remote_dircopy(tmpurl01, tmplocaldstpath)
        return localdstpath

    def copy_localhost_pdf_docid_data_files(self, idocid):
        localdstpath = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), '')
        for t in ['pdf_total_pages']:
            tmpdst = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), '')
            tmpsrc = os.path.join(self.__doc_process_opath, 'docs', str(idocid), t)
            if os.path.isfile(tmpsrc):
                self.createdir(tmpdst)
                shutil.copy2(tmpsrc, tmpdst)
            pass
        for t in ['output_html/']:
            tmpdst = os.path.join(self.__tmp_extract_opath[:], 'docs', str(idocid), t, '')
            tmpsrc = os.path.join(self.__doc_process_opath, 'docs', str(idocid), t, '')
            if os.path.isdir(tmpsrc):
                self.createdir(tmpdst)
                copy_tree(tmpsrc, tmpdst)
            pass
        return localdstpath

    def copypdfdocid(self, idocid):
        localpath = self.copy_remote_pdf_docid_data_files(idocid)
        #localpath = self.copy_localhost_pdf_docid_data_files(idocid)
        return

    def copydocid(self, idocid):
        res = None
        if 1 and (self.__doctype == 'pdf'):
            res = self.copypdfdocid(idocid)
        else:
            res = self.copyhtmldocid(idocid)
        return res

    def __process_docids(self, idocidlst):
        def processdocidlst(ilst, tsize):
            for idx, tmpdocid in ilst:
                t0 = time.time()
                self.copydocid(tmpdocid)
                t1 = time.time()
                print '%s/%s: %s - %s' %(str(idx), str(tsize), str(tmpdocid), str(t1-t0))
                pass
            return

        if idocidlst:
            psize = 50
            tmp_docid_lst = []
            for i, docid in enumerate(idocidlst):
                ttup = (i, docid)
                tmp_docid_lst.append(ttup)

            tsize = len(tmp_docid_lst)
            batch_docid_lst = self.get_batch(tmp_docid_lst, psize)
            if 0 and (len(batch_docid_lst) > 1):
                if batch_docid_lst:
                    plst = pprocess.pmap(lambda x:processdocidlst(batch_docid_lst[x], tsize), range(0, len(batch_docid_lst)), pprocess.get_number_of_cores())
                    for each in plst:
                        pass
                    pass
                pass

            else:
                resd = processdocidlst(tmp_docid_lst, tsize)
                pass
            pass

        return

    def __get_training_datalst(self, ilst, trcopyflag=1):
        resd = {}
        if 1 and ilst:
            dlst = []
            tmpd = {}
            tmplst = []
            for i, eachttup in enumerate(ilst):
                tmp_docid, tmp_pageno, tmprefstr, tmp_xmlid, tmp_taxonomy, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_seidx_ttup, tmp_extracted_date, tmp_batch = eachttup[:11]
                tmp_docid = str(tmp_docid)
                ttup = (tmp_docid, tmp_pageno, tmprefstr, tmp_xmlid, tmp_taxonomy, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_seidx_ttup, tmp_extracted_date, tmp_batch)
                tmplst.append(ttup)
                if tmpd.get(tmp_docid, None) is None:
                    tmpd[tmp_docid] = {}
                tmpd[tmp_docid][tmp_xmlid] = 1
            tmp_docid_lst = tmpd.keys()

            if trcopyflag: self.__process_docids(tmp_docid_lst[:])

            xmlid2textd = {}
            for idx0, tmp_docid in enumerate(tmp_docid_lst[:]):
                pass

            dlst = []
            for i, each in enumerate(tmplst):
                tmp_norm_value = ''
                tmp_extracted_date = ''
                tmp_batch = ''
                tmp_docid, tmp_pageno, tmprefstr, tmp_xmlid, tmp_taxonomy, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_seidx_ttup, tmp_extracted_date, tmp_batch = each
                ttup = (tmp_extracted_date, tmp_docid, tmp_pageno, tmp_xmlid, tmp_seidx_ttup, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_taxonomy)
                dlst.append(ttup)
                pass

            resd = {'data': dlst}
        return resd

    def __get_training_xlsx(self, inputfname, isheetname):
        tlst = []
        if 1 and os.path.isfile(inputfname) and isheetname:
            tmpdatad = self.__readExcel(inputfname)
            tmplst = tmpdatad.get(isheetname, [])
            for each in tmplst:
                t = [elm.strip() for elm in each]
                tlst.append(t)
            pass
        return tlst

    def __get_training_text(self, inputfname, batchname='batchname'):
        tlst = []
        if os.path.isfile(inputfname):
            tmp1 = self.read_file_lines(inputfname)
            for each in tmp1:
                t = each.split('\t')
                t = [elm.strip() for elm in t]
                t.append(batchname)
                tlst.append(t)
            pass
        return tlst

    def __gettrainingdata(self, iprojectid, iurlid):
        # source 3
        p = self.__get_urlid_inputpath()
        tmplst = []
        inputfname0 = os.path.join(p, 'trainingdata_srctxt_%s_%s.txt'%(str(iprojectid), str(iurlid)))
        tmplst += self.__get_training_text(inputfname0, 'Batch4')
        print len(tmplst)
        #inputfname1 = os.path.join(p, 'trainingdata_%s_%s.txt'%(str(iprojectid), str(iurlid)))
        #tmplst += self.__get_training_text(inputfname1, 'Batch4')
        #inputfname2 = os.path.join(p, 'trainingdata_%s_%s_2.txt'%(str(iprojectid), str(iurlid)))
        #tmplst += self.__get_training_text(inputfname2, 'Batch5')
        #inputfname3 = os.path.join(p, 'trainingdata_%s_%s_3.txt'%(str(iprojectid), str(iurlid)))
        #tmplst += self.__get_training_text(inputfname3, 'Batch5')
        #inputfname4 = os.path.join(p, 'trainingdata_%s_%s_4.txt'%(str(iprojectid), str(iurlid)))
        #tmplst += self.__get_training_text(inputfname4, 'Batch5')
        print len(tmplst)
        tmptrainingdatalst4 = []
        d0 = {}
        d1 = {}
        for each in tmplst:
            tmprefstr = ''
            #tmp_extracted_date, tmp_docid, tmp_xmlid, tmp_seidx_ttup, tmp_extracted_value, tmp_norm_value, tmp_taxonomy, tmp_pageno, tmp_batch = each[:9]
            #ttup = (tmp_docid, tmp_pageno, tmprefstr, tmp_xmlid, tmp_taxonomy, tmp_extracted_value, tmp_norm_value, tmp_seidx_ttup, tmp_extracted_date, tmp_batch)
            tmp_extracted_date, tmp_docid, tmp_xmlid, tmp_seidx_ttup, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_taxonomy, tmp_pageno, tmpstatus, tmp_batch = each[:11]
            ttup = (tmp_docid, tmp_pageno, tmprefstr, tmp_xmlid, tmp_taxonomy, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_seidx_ttup, tmp_extracted_date, tmp_batch)
            d0[tmp_docid] = 1
            d1[tmp_extracted_date] = 1
            tmptrainingdatalst4.append(ttup)
            pass
        trainingdatalst = tmptrainingdatalst4[:]
        print len(d0), len(d1), len(trainingdatalst)
        return trainingdatalst

    def __get_training_cleandata(self, opath, iprojectid, iurlid, rerun=0):
        ofname = self.getdcdatapath(opath, 'trainingdata', 'training_data.slv')
        resd = self.read_from_shelve(ofname)
        if 1 and ((not resd) or rerun):
            resd = {}
            if 1:
                tlst = self.__gettrainingdata(iprojectid, iurlid)
                resd = self.__get_training_datalst(tlst[:])
                print len(tlst)

                # save
                self.write_to_shelve(ofname, resd)
                print 'Writing training data shelve:', ofname
                pass
            pass
        return resd

    def __get_training_acceptance_cleandata(self, opath, iprojectid, iurlid, rerun=0):
        def gettrdata(tmpprojectid, tmpurlid):
            # source 3
            p = self.__get_urlid_inputpath()
            tmplst = []
            inputfname0 = os.path.join(p, 'trainingdata_acceptance_%s_%s.txt'%(str(tmpprojectid), str(tmpurlid)))
            tmplst += self.__get_training_text(inputfname0, 'Batch4')
            print len(tmplst)
            tmptrainingdatalst4 = []
            d0 = {}
            d1 = {}
            for each in tmplst:
                tmprefstr = ''
                tmp_extracted_date, tmp_docid, tmp_xmlid, tmp_seidx_ttup, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_taxonomy, tmp_pageno, tmpstatus, tmp_batch = each[:11]
                ttup = (tmp_docid, tmp_pageno, tmprefstr, tmp_xmlid, tmp_taxonomy, tmporgtext, tmp_extracted_value, tmp_norm_value, tmp_seidx_ttup, tmp_extracted_date, tmp_batch)
                d0[tmp_docid] = 1
                d1[tmp_extracted_date] = 1
                tmptrainingdatalst4.append(ttup)
                pass
            trainingdatalst = tmptrainingdatalst4[:]
            print len(d0), len(d1), len(trainingdatalst)
            return trainingdatalst

        ofname = self.getdcdatapath(opath, 'trainingdata', 'training_acceptance_data.slv')
        resd = self.read_from_shelve(ofname)
        if 1 and ((not resd) or rerun):
            resd = {}
            if 1:
                tlst = gettrdata(iprojectid, iurlid)
                resd = self.__get_training_datalst(tlst[:], 0)
                print len(tlst)

                # save
                self.write_to_shelve(ofname, resd)
                print 'Writing training data shelve:', ofname
                pass
            pass
        return resd

    def process_training_data(self):
        res = None
        opath = self.__dataclassifyopath[:]
        trainingdatad = self.__get_training_cleandata(opath, self.projectid, self.urlid, 0)
        tracceptdatad = self.__get_training_acceptance_cleandata(opath, self.projectid, self.urlid, 0)

        # training document process
        #self.__txtObj.get_html_classificaion2(opath, trainingdatad, {})

        #res = self.__txtObj.process_training_data(trainingdatad)
        res = self.__txtObj.process_training_datav2(trainingdatad, tracceptdatad)
        #self.__txtObj.updatetrainingintfdata()
        return res

    def getcustomindex2text(self, ilst):
        tmpp = '/var/www/html/INFOSIEVE_PROJECTS/HKSEGD/data/output/'
        for tup in ilst:
            tmpdocid, pagenolst = tup
            for tmppno in pagenolst:
                ofname = os.path.join(tmpp, str(tmpdocid), 'MetaInfo', '%s_%s.slv'%(str(tmpdocid), str(tmppno)))
                tmpurl = 'http://172.16.20.10/INFOSIEVE_PROJECTS/HKSEGD/data/output/%s/output_html/%s.html'%(tmpdocid, tmppno)
                print (tmpurl, ofname)
                tmpd = self.__txtObj.getcust2text(tmpdocid, tmppno, tmpurl)
                self.write_to_shelve(ofname, tmpd)
            pass
        return

    def toapplyprocessdoc(self, idoctuplst):
        resd = self.__txtObj.processdoc(idoctuplst)
        return resd

    def rundoc(self, tmplst):
        opath = self.__dataclassifyopath[:]
        resd = self.__txtObj.toapply_textdataextraction(opath, tmplst)
        return resd

    def get_training_data(self):
        res = self.__txtObj.get_training_data()
        return res

    def toapplytextextraction(self, ibtup, itrainingtup=None):
        if not itrainingtup:
            itrainingtup = self.__txtObj.get_training_data()
        resd = self.__txtObj.toapplydatatextextract(itrainingtup, ibtup)
        return resd

    def displayresults(self, idata):
        self.__txtObj.displayresults(idata.keys(), idata)
        return

    def rundocdbg(self, tmplst):
        tmpd0 = {}
        opath = self.__dataclassifyopath[:]
        if tmplst:
            tmpd0 = self.__txtObj.toapply_textdataextraction(opath, tmplst)
            if 1:
                for idx, doctup in enumerate(tmplst):
                    page_no = doctup[1].split('/')[-1].split('.')[0]
                    d = tmpd0.get(str(idx), {})
                    tmptaxolst = d.keys()
                    tmptaxolst.sort()
                    tsize = len(tmptaxolst)
                    for i, tmptn in enumerate(tmptaxolst):
                        print '%s/%s - %s' %(str(i+1), str(tsize), tmptn)
                        vlst = d.get(tmptn, [])
                        for j in range(0, len(vlst)):
                            gkey = vlst[j][-1].get('gkey', None)
                            gval = vlst[j][-1].get('gval', None)
                            print '     :', j, vlst[j]
                            print '     key:', (gkey, gval)
                        pass
                    pass
                pass
            pass
        return tmpd0

    def debug(self):
        return
